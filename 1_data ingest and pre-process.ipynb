{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af7b3a7c-1ec4-46e1-85a1-9316fa0e4be3",
   "metadata": {},
   "source": [
    "Steps in this notebook:\n",
    "1. Loading functions used in text pre-processing\n",
    "2. Ingest and process data file (see sample data file and data dictionary for additional clarification)\n",
    "3. Run text functions from part 1 and export new file to pull into deep learning model for step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84e52bf-db71-438a-a144-d0b0e188e521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cd62411-f1c7-4cf5-b312-7c0e98cf81ea",
   "metadata": {},
   "source": [
    "# Init: Load Libraries and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb47a848-b1f3-471f-aff4-535d90360dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import string\n",
    "from textblob import TextBlob  \n",
    "import os\n",
    "import re\n",
    "\n",
    "np.random.seed(67)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343e4418-f184-47b8-a0c7-6f3567a5901a",
   "metadata": {},
   "source": [
    "## Feature Engineering Functions"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4493dd6a-3fc4-456d-a321-fd1b82df5b7e",
   "metadata": {},
   "source": [
    "Function to provide polarity and subjectivity scores (based on subject line) for interpretation of deep learning results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b73d04-d573-450d-9aec-8ba59399ded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function below uses pre-built model for sentiment classification from TextBlob\n",
    "# https://textblob.readthedocs.io/en/dev/quickstart.html\n",
    "\n",
    "def polarity_scorer(input_text):\n",
    "    \"\"\"This function operates on a column in a data frame using apply().\n",
    "    Takes a column as an input and returns a tuple of the polarity score and subjectivity score\n",
    "    use .tolist() to split into separate columns, like here: https://stackoverflow.com/questions/29550414/how-to-split-column-of-tuples-in-pandas-dataframe\"\"\"\n",
    "    text = TextBlob(input_text)\n",
    "    polarity_score = text.sentiment.polarity\n",
    "    subjectivity_score = text.sentiment.subjectivity\n",
    "    \n",
    "    return polarity_score, subjectivity_score"
   ]
  },
  {
   "cell_type": "raw",
   "id": "20e5489d-d985-44c2-a67e-8bb860685712",
   "metadata": {},
   "source": [
    "Function to create an extra column with top tokens from each subject line, which is helpful for explaining model results in later stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5949cf39-c7a8-46ca-896e-30d3412f2c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "punctuations = string.punctuation #this is a python module which contains all the punctuations characters in English (and probably other languages too)\n",
    "stopwords = list(STOP_WORDS)\n",
    "\n",
    "def spacy_tokenizer(input_text):\n",
    "    \"\"\"removes stop words and punctuation from a document, converts all tokens to lower case\n",
    "    and combines all tokens into one string.\n",
    "    used in this example it appends a new column to a dataframe through apply()\"\"\"\n",
    "    processed_text = re.sub(r\"http\\S+\", '', input_text) # remove URLS, https://stackoverflow.com/questions/24399820/expression-to-remove-url-links-from-twitter-tweet\n",
    "    mytokens = nlp(processed_text)\n",
    "    mytokens = [word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "    mytokens = [word for word in mytokens if word not in stopwords and word not in punctuations ]\n",
    "    mytokens = \" \".join([i for i in mytokens])\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7af328-678c-4d6d-919d-2974436ccc86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83b3a419-8aab-4472-b311-6ff54d4415c3",
   "metadata": {},
   "source": [
    "# Import Data and process personalized subject lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490bddae-bf3e-49d4-8b49-15617b81af84",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('sample data files/input_for_step_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03b1435-8c99-4fc2-8fab-14ae1916b085",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22ed847-e8ec-4d68-b586-ce545cf95e78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b30e313-b61f-4114-b1c7-d174e565de5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.subject.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5771546c-1017-4997-91e8-98de75448d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename({'subject':'text'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "529008a8-75b9-4a01-808a-1921fe03c220",
   "metadata": {},
   "source": [
    "removing text from macros to put recipient name in subject line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd7a202-fa82-4b66-84ba-c31226c9562a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.text = [re.sub('[%%](.*)[%%]', '', text) for text in data.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80c0ec2-8000-45e3-9d65-7c5598acc43b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c7123f-2aba-4bcb-90a7-d2c670c98f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['send_group'] = data.email_name.str[:16]\n",
    "data['Open_Rate_nw'] = data.unique_opens / data.emails_sent\n",
    "data['Click_Rate_nw'] = data.unique_clicks / data.emails_sent\n",
    "data['Donation_Rate_nw'] = data.gifts / data.emails_sent\n",
    "data['revenue_1k_new'] = data.revenue / (data.emails_sent/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10caf562-ee86-464e-a516-f67d9f68916c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.send_dt = pd.to_datetime(data.send_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7017ee8a-2860-4d71-8d5c-d9bdd2ea5732",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['month'] = pd.DatetimeIndex(data.send_dt).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da3d80e-eda3-43ae-8b43-c246ca424aab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956d0bcc-2769-46a5-b5ae-ce782918a68a",
   "metadata": {},
   "source": [
    "# Processing new cols with NLP and Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9859e800-014a-4ae3-8750-e96ea00c8dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calls functions through apply(), returns a tuple then splits the results into 2 columns\n",
    "data.text = data.text.astype('str') \n",
    "\n",
    "data[['polarity_score', 'subjectivity_score']] = pd.DataFrame(data.text.apply(polarity_scorer).tolist(), index = data.index)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8974399-cb91-4e38-92f9-beaaad1a4733",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['processed_text'] = data.text.apply(spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652eedb7-bec8-40dd-bd56-10cb6d059d91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "02201240-bd99-4523-8fc1-5a1b4d9c1635",
   "metadata": {},
   "source": [
    "Note on file naming conventions: each file is named after the (next) step in the pipeline which it feeds. So the very first file is called 'input for step 1.csv' and then then file after that is named based on feeding into the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4037fc9-5841-4ce0-ba48-7e5b421d54a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('sample data files/input_for_step_2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1186316-d73a-4b5b-9069-0cba4b1d8a45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
